{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39be0724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "\n",
    "def empirical_normal_res(X_obs: np.ndarray, N: int, random_seed: int = None):\n",
    "    \"\"\"\n",
    "    Sequentially resample up to N points from empirical normal.\n",
    "    Each new point is drawn from N(mean, cov) of all existing points (original + generated so far).\n",
    "    Returns: stacked array of [X_obs, new_samples]\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    X_gen = X_obs.copy()\n",
    "    n, d = X_obs.shape\n",
    "    n_to_generate = N - n\n",
    "    new_samples = []\n",
    "    for _ in range(n_to_generate):\n",
    "        mean = X_gen.mean(axis=0)\n",
    "        cov = np.cov(X_gen, rowvar=False)\n",
    "        cov += 1e-6 * np.eye(d)\n",
    "        sample = rng.multivariate_normal(mean, cov)\n",
    "        new_samples.append(sample)\n",
    "        X_gen = np.vstack([X_gen, sample])\n",
    "    if new_samples:\n",
    "        return np.vstack([X_obs, np.array(new_samples)])\n",
    "    else:\n",
    "        return X_obs.copy()\n",
    "\n",
    "\n",
    "def oversample_resampling(X_obs, Y_obs, y, random_seed=None):\n",
    "    mask = Y_obs == y\n",
    "    X_majority = X_obs[~mask]\n",
    "    Y_majority = Y_obs[~mask]\n",
    "    N = np.sum(~mask)\n",
    "    X_new = empirical_normal_res(X_obs[mask], N, random_seed)\n",
    "    X_out = np.vstack([X_majority, X_new])\n",
    "    Y_out = np.concatenate([Y_majority, np.full(N, y)])\n",
    "    return X_out, Y_out\n",
    "\n",
    "\n",
    "def undersample_random(X_obs, Y_obs, y, random_seed=None):\n",
    "    rus = RandomUnderSampler(random_state=random_seed)\n",
    "    X_out, Y_out = rus.fit_resample(X_obs, Y_obs)\n",
    "    return X_out, Y_out\n",
    "\n",
    "\n",
    "def oversample_random(X_obs, Y_obs, y, random_seed=None):\n",
    "    ros = RandomOverSampler(random_state=random_seed)\n",
    "    X_out, Y_out = ros.fit_resample(X_obs, Y_obs)\n",
    "    return X_out, Y_out\n",
    "\n",
    "def oversample_smote(X_obs, Y_obs, y, random_seed=None):\n",
    "    smote = SMOTE(random_state=random_seed)\n",
    "    X_out, Y_out = smote.fit_resample(X_obs, Y_obs)\n",
    "    return X_out, Y_out\n",
    "\n",
    "def no_resampling(X_obs, Y_obs, y, random_seed=None):\n",
    "    \"\"\"\n",
    "    No resampling, just return the original data.\n",
    "    \"\"\"\n",
    "    return X_obs.copy(), Y_obs.copy()\n",
    "\n",
    "def test_oversample_resampling():\n",
    "    n, m = 30, 4\n",
    "    X_obs = np.random.randn(n, m)\n",
    "    Y_obs = np.zeros(n, dtype=int)\n",
    "    Y_obs[:10] = 1  # Minority class: 10 samples, Majority class: 20 samples\n",
    "    np.random.shuffle(Y_obs)\n",
    "    X_out, Y_out = oversample_resampling(X_obs, Y_obs, y=1)\n",
    "    assert X_obs.shape == (n, m)\n",
    "    assert X_out.shape[0] == 2 * np.sum(Y_obs == 0)\n",
    "    assert X_out.shape[1] == m\n",
    "    assert np.sum(Y_out == 0) == np.sum(Y_out == 1)\n",
    "    X_out, Y_out = oversample_random(X_obs, Y_obs, y=1)\n",
    "    assert X_obs.shape == (n, m)\n",
    "    assert X_out.shape[0] == 2 * np.sum(Y_obs == 0)\n",
    "    assert X_out.shape[1] == m\n",
    "    assert np.sum(Y_out == 0) == np.sum(Y_out == 1)\n",
    "    X_out, Y_out = oversample_smote(X_obs, Y_obs, y=1)\n",
    "    assert X_obs.shape == (n, m)\n",
    "    assert X_out.shape[0] == 2 * np.sum(Y_obs == 0)\n",
    "    assert X_out.shape[1] == m\n",
    "    assert np.sum(Y_out == 0) == np.sum(Y_out == 1)\n",
    "    X_out, Y_out = undersample_random(X_obs, Y_obs, y=1)\n",
    "    assert X_obs.shape == (n, m)\n",
    "    assert X_out.shape[0] == 2 * np.sum(Y_obs == 1)\n",
    "    assert X_out.shape[1] == m\n",
    "    assert np.sum(Y_out == 0) == np.sum(Y_out == 1)\n",
    "    print('Test passed.')\n",
    "\n",
    "test_oversample_resampling()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719611f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_predict_classifier(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        X_test,\n",
    "        clf,  # Classifier to use, e.g., RandomForestClassifier or LogisticRegression\n",
    "        sampling_method=None,  # Function to use for resampling, e.g., oversample_resampling, undersample_random, or oversample_random\n",
    "        y = 1,  # Class to oversample, only used if sampling_method is not None\n",
    "        random_seed=None,\n",
    "        B=1,  # Deep ensemble\n",
    "):\n",
    "    if sampling_method is not None:\n",
    "        X_train, Y_train = sampling_method(X_train, Y_train, y, random_seed=random_seed)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def fit_predict_proba_classifier(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        X_test,\n",
    "        clf,  # Classifier to use, e.g., RandomForestClassifier or LogisticRegression\n",
    "        sampling_method=None,  # Function to use for resampling, e.g., oversample_resampling, undersample_random, or oversample_random\n",
    "        y = 1,  # Class to oversample, only used if sampling_method is not None\n",
    "        random_seed=None,\n",
    "        B=1,  # Number of bootstraps for Deep ensemble\n",
    "):\n",
    "    Y_proba_bootstraps = []\n",
    "    seed = random_seed\n",
    "    for i in range(B):\n",
    "        # Updating random seed for each bootstrap\n",
    "        if random_seed is not None:\n",
    "            seed += 1\n",
    "        \n",
    "        # Resampling for class imbalance\n",
    "        if sampling_method is not None:\n",
    "            X_train, Y_train = sampling_method(X_train, Y_train, y, random_seed=seed)\n",
    "        \n",
    "        # Fitting the classifier\n",
    "        clf.random_state = seed\n",
    "        clf.fit(X_train, Y_train)\n",
    "\n",
    "        # Extracting probabilities\n",
    "        Y_proba = clf.predict_proba(X_test)  # Shape: (n_samples_test, n_classes)\n",
    "        Y_proba_bootstraps.append(Y_proba)  # Shape: (B, n_samples_test, n_classes)\n",
    "    \n",
    "    # Averaging the probabilities across bootstraps\n",
    "    Y_proba_avg = np.mean(Y_proba_bootstraps, axis=0)  # Shape: (n_samples_test, n_classes)\n",
    "\n",
    "    return Y_proba_avg\n",
    "\n",
    "def get_entropy(Y_proba):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of the predicted probabilities.\n",
    "    :param Y_proba: Predicted probabilities of shape (n_samples, n_classes)\n",
    "    :return: Entropy values for each sample\n",
    "    \"\"\"\n",
    "    # Avoid log(0) by adding a small constant\n",
    "    epsilon = 1e-10\n",
    "    Y_proba = np.clip(Y_proba, epsilon, 1 - epsilon)\n",
    "    return -np.sum(Y_proba * np.log(Y_proba), axis=1)  # Shape: (n_samples,)\n",
    "\n",
    "def get_1_minus_sumsq(Y_proba):\n",
    "    \"\"\"\n",
    "    Calculate 1 - sum of squares of predicted probabilities.\n",
    "    :param Y_proba: Predicted probabilities of shape (n_samples, n_classes)\n",
    "    :return: 1 - sum of squares for each sample\n",
    "    \"\"\"\n",
    "    return 1 - np.sum(Y_proba ** 2, axis=1)  # Shape: (n_samples,)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, recall_score, precision_score, matthews_corrcoef, average_precision_score, roc_auc_score\n",
    "from functools import partial\n",
    "SCORES_MAP = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'balanced_accuracy': balanced_accuracy_score,\n",
    "    'f1': f1_score,\n",
    "    'f1_1': partial(f1_score, pos_label=1),\n",
    "    'f1_0': partial(f1_score, pos_label=0),\n",
    "    'recall_1': partial(recall_score, pos_label=1),\n",
    "    'recall_0': partial(recall_score, pos_label=0),\n",
    "    'precision_1': partial(precision_score, pos_label=1),\n",
    "    'precision_0': partial(precision_score, pos_label=0),\n",
    "    'matthews_corrcoef': matthews_corrcoef,\n",
    "    'average_precision': average_precision_score,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "def get_scores(\n",
    "        Y_pred,\n",
    "        Y_true,\n",
    "        scores_map: dict = SCORES_MAP,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate various scores based on the predictions and true labels.\n",
    "    :param Y_pred: Predicted labels or probabilities.  # If probabilities, will take the class with the highest probability.\n",
    "    :param Y_true: True labels.\n",
    "    :param scores_map: Dictionary mapping score names to scoring functions.\n",
    "    :return: Dictionary of scores.\n",
    "    \"\"\"\n",
    "    if Y_pred.ndim == 2 and Y_pred.shape[1] > 1:\n",
    "        # If Y_pred is probabilities, take the class with the highest probability\n",
    "        Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    return {name: score_func(Y_true, Y_pred)\n",
    "            for name, score_func in scores_map.items() if hasattr(score_func, '__call__')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561356c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_few_ones(X, Y, one_ratio=0.1, random_state=None):\n",
    "    \"\"\"\n",
    "    Function to create unbalanced dataset for training.\n",
    "    X_train: all zeros + 5% of the ones.\n",
    "    X_test: remaining ones.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "    Y : np.ndarray, shape (n_samples,)\n",
    "    one_ratio : float\n",
    "        Proportion of ones to include in train.\n",
    "    random_state : int or None\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train, X_test, Y_train, Y_test\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    ones_idx = np.where(Y == 1)[0]\n",
    "    zeros_idx = np.where(Y == 0)[0]\n",
    "\n",
    "    n_train_ones = int(one_ratio * len(ones_idx))\n",
    "    n_train_zeros = len(ones_idx) - n_train_ones\n",
    "    train_ones_idx = rng.choice(ones_idx, size=n_train_ones, replace=False)\n",
    "    train_zeros_idx = rng.choice(zeros_idx, size=n_train_zeros, replace=False)\n",
    "    \n",
    "    train_idx = np.concatenate([train_zeros_idx, train_ones_idx])\n",
    "    test_idx = np.setdiff1d(np.arange(len(Y)), train_idx)\n",
    "\n",
    "    # Shuffle\n",
    "    rng.shuffle(train_idx)\n",
    "    rng.shuffle(test_idx)\n",
    "\n",
    "    X_train = X[train_idx]\n",
    "    Y_train = Y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320f1cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:03<00:00,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: Diabetes dataset\n",
      "Average scores across iterations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oversample_resampling</th>\n",
       "      <th>oversample_random</th>\n",
       "      <th>oversample_smote</th>\n",
       "      <th>undersample_random</th>\n",
       "      <th>no_resampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.451064</td>\n",
       "      <td>0.298553</td>\n",
       "      <td>0.372085</td>\n",
       "      <td>0.641021</td>\n",
       "      <td>0.240170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.594376</td>\n",
       "      <td>0.546863</td>\n",
       "      <td>0.574483</td>\n",
       "      <td>0.637854</td>\n",
       "      <td>0.517921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.501382</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.737434</td>\n",
       "      <td>0.090819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1</th>\n",
       "      <td>0.501382</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.737434</td>\n",
       "      <td>0.090819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0</th>\n",
       "      <td>0.384771</td>\n",
       "      <td>0.360430</td>\n",
       "      <td>0.373840</td>\n",
       "      <td>0.417826</td>\n",
       "      <td>0.346872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_1</th>\n",
       "      <td>0.352086</td>\n",
       "      <td>0.127059</td>\n",
       "      <td>0.232299</td>\n",
       "      <td>0.643209</td>\n",
       "      <td>0.048342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_0</th>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_1</th>\n",
       "      <td>0.892099</td>\n",
       "      <td>0.935064</td>\n",
       "      <td>0.915080</td>\n",
       "      <td>0.873941</td>\n",
       "      <td>0.934751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_0</th>\n",
       "      <td>0.250235</td>\n",
       "      <td>0.221586</td>\n",
       "      <td>0.234885</td>\n",
       "      <td>0.317093</td>\n",
       "      <td>0.210404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <td>0.163694</td>\n",
       "      <td>0.119887</td>\n",
       "      <td>0.149178</td>\n",
       "      <td>0.229273</td>\n",
       "      <td>0.068928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision</th>\n",
       "      <td>0.830695</td>\n",
       "      <td>0.814009</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>0.845376</td>\n",
       "      <td>0.803029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.594376</td>\n",
       "      <td>0.546863</td>\n",
       "      <td>0.574483</td>\n",
       "      <td>0.637854</td>\n",
       "      <td>0.517921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   oversample_resampling  oversample_random  oversample_smote  \\\n",
       "accuracy                        0.451064           0.298553          0.372085   \n",
       "balanced_accuracy               0.594376           0.546863          0.574483   \n",
       "f1                              0.501382           0.220799          0.368782   \n",
       "f1_1                            0.501382           0.220799          0.368782   \n",
       "f1_0                            0.384771           0.360430          0.373840   \n",
       "recall_1                        0.352086           0.127059          0.232299   \n",
       "recall_0                        0.836667           0.966667          0.916667   \n",
       "precision_1                     0.892099           0.935064          0.915080   \n",
       "precision_0                     0.250235           0.221586          0.234885   \n",
       "matthews_corrcoef               0.163694           0.119887          0.149178   \n",
       "average_precision               0.830695           0.814009          0.824098   \n",
       "roc_auc                         0.594376           0.546863          0.574483   \n",
       "\n",
       "                   undersample_random  no_resampling  \n",
       "accuracy                     0.641021       0.240170  \n",
       "balanced_accuracy            0.637854       0.517921  \n",
       "f1                           0.737434       0.090819  \n",
       "f1_1                         0.737434       0.090819  \n",
       "f1_0                         0.417826       0.346872  \n",
       "recall_1                     0.643209       0.048342  \n",
       "recall_0                     0.632500       0.987500  \n",
       "precision_1                  0.873941       0.934751  \n",
       "precision_0                  0.317093       0.210404  \n",
       "matthews_corrcoef            0.229273       0.068928  \n",
       "average_precision            0.845376       0.803029  \n",
       "roc_auc                      0.637854       0.517921  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DIABETES DATASET\n",
    "from sklearn.datasets import load_diabetes, make_classification\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "feature_names = diabetes.feature_names\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "sex_idx = feature_names.index('sex')\n",
    "# Make binary target: 1 for male (sex > 0), 0 for female (sex <= 0)\n",
    "Y = (X[:, sex_idx] > 0).astype(int)\n",
    "df[\"Y\"] = Y\n",
    "df = df.drop(columns=\"sex\").dropna()\n",
    "X = df.drop(columns=\"Y\").values\n",
    "Y = df[\"Y\"].values\n",
    "\n",
    "\n",
    "# n_train = 500\n",
    "# n_test = 500\n",
    "ones_ratio = 0.1\n",
    "\n",
    "sampling_methods = {\n",
    "    \"oversample_resampling\": oversample_resampling,\n",
    "    \"oversample_random\": oversample_random,\n",
    "    \"oversample_smote\": oversample_smote,\n",
    "    \"undersample_random\": undersample_random,\n",
    "    \"no_resampling\": no_resampling,\n",
    "}\n",
    "avg_scores = None\n",
    "iter = 25\n",
    "B = 10\n",
    "\n",
    "\n",
    "for i in tqdm(range(iter)):\n",
    "    X_obs, X_test, Y_obs, Y_test = train_with_few_ones(X, Y, one_ratio=ones_ratio, random_state=421+i)\n",
    "\n",
    "    scores_dict = {}\n",
    "    for name, sampling_method in sampling_methods.items():\n",
    "        Y_probas = fit_predict_proba_classifier(\n",
    "            X_obs, Y_obs, X_test,\n",
    "            clf=RandomForestClassifier(),\n",
    "            sampling_method=sampling_method,\n",
    "            random_seed=412+i,\n",
    "            y=1,\n",
    "            B=B,  # Number of bootstraps for Deep ensemble\n",
    "        )\n",
    "        Y_pred = np.argmax(Y_probas, axis=1)\n",
    "        method_scores_dict = get_scores(Y_pred, Y_test)\n",
    "        scores_dict[name] = method_scores_dict\n",
    "    # Average scores across iterations\n",
    "    if avg_scores is None:\n",
    "        avg_scores = pd.DataFrame(scores_dict)\n",
    "    else:\n",
    "        avg_scores += pd.DataFrame(scores_dict)\n",
    "avg_scores /= iter\n",
    "# print_scores_table(scores_dict)\n",
    "print(\"DATASET: Diabetes dataset\")\n",
    "print(\"Average scores across iterations:\")\n",
    "display(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b6dcad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:45<00:00,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: Diabetes dataset\n",
      "Average scores across iterations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oversample_resampling</th>\n",
       "      <th>oversample_random</th>\n",
       "      <th>oversample_smote</th>\n",
       "      <th>undersample_random</th>\n",
       "      <th>no_resampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.970847</td>\n",
       "      <td>0.960678</td>\n",
       "      <td>0.961356</td>\n",
       "      <td>0.978305</td>\n",
       "      <td>0.958644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.984074</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.978889</td>\n",
       "      <td>0.984519</td>\n",
       "      <td>0.977407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.983576</td>\n",
       "      <td>0.977691</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.976624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1</th>\n",
       "      <td>0.983576</td>\n",
       "      <td>0.977691</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.976624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0</th>\n",
       "      <td>0.866973</td>\n",
       "      <td>0.830253</td>\n",
       "      <td>0.836455</td>\n",
       "      <td>0.891866</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_1</th>\n",
       "      <td>0.968148</td>\n",
       "      <td>0.957037</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.977037</td>\n",
       "      <td>0.954815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_0</th>\n",
       "      <td>0.778413</td>\n",
       "      <td>0.726760</td>\n",
       "      <td>0.736753</td>\n",
       "      <td>0.820556</td>\n",
       "      <td>0.704380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.829729</td>\n",
       "      <td>0.835732</td>\n",
       "      <td>0.888842</td>\n",
       "      <td>0.816755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision</th>\n",
       "      <td>0.997301</td>\n",
       "      <td>0.996359</td>\n",
       "      <td>0.996422</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.996171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.984074</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.978889</td>\n",
       "      <td>0.984519</td>\n",
       "      <td>0.977407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   oversample_resampling  oversample_random  oversample_smote  \\\n",
       "accuracy                        0.970847           0.960678          0.961356   \n",
       "balanced_accuracy               0.984074           0.978519          0.978889   \n",
       "f1                              0.983576           0.977691          0.977941   \n",
       "f1_1                            0.983576           0.977691          0.977941   \n",
       "f1_0                            0.866973           0.830253          0.836455   \n",
       "recall_1                        0.968148           0.957037          0.957778   \n",
       "recall_0                        1.000000           1.000000          1.000000   \n",
       "precision_1                     1.000000           1.000000          1.000000   \n",
       "precision_0                     0.778413           0.726760          0.736753   \n",
       "matthews_corrcoef               0.864982           0.829729          0.835732   \n",
       "average_precision               0.997301           0.996359          0.996422   \n",
       "roc_auc                         0.984074           0.978519          0.978889   \n",
       "\n",
       "                   undersample_random  no_resampling  \n",
       "accuracy                     0.978305       0.958644  \n",
       "balanced_accuracy            0.984519       0.977407  \n",
       "f1                           0.987930       0.976624  \n",
       "f1_1                         0.987930       0.976624  \n",
       "f1_0                         0.891866       0.817632  \n",
       "recall_1                     0.977037       0.954815  \n",
       "recall_0                     0.992000       1.000000  \n",
       "precision_1                  0.999273       1.000000  \n",
       "precision_0                  0.820556       0.704380  \n",
       "matthews_corrcoef            0.888842       0.816755  \n",
       "average_precision            0.997327       0.996171  \n",
       "roc_auc                      0.984519       0.977407  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WINE DATASET\n",
    "from sklearn.datasets import load_wine\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "\n",
    "# keep only two classes: 0 and 1\n",
    "mask = Y != 2\n",
    "X = X[mask]\n",
    "Y = Y[mask]\n",
    "\n",
    "\n",
    "# n_train = 500\n",
    "# n_test = 500\n",
    "ones_ratio = 0.25\n",
    "\n",
    "sampling_methods = {\n",
    "    \"oversample_resampling\": oversample_resampling,\n",
    "    \"oversample_random\": oversample_random,\n",
    "    \"oversample_smote\": oversample_smote,\n",
    "    \"undersample_random\": undersample_random,\n",
    "    \"no_resampling\": no_resampling,\n",
    "}\n",
    "avg_scores = None\n",
    "iter = 25\n",
    "B = 10\n",
    "\n",
    "\n",
    "for i in tqdm(range(iter)):\n",
    "    X_obs, X_test, Y_obs, Y_test = train_with_few_ones(X, Y, one_ratio=ones_ratio, random_state=421+i)\n",
    "\n",
    "    scores_dict = {}\n",
    "    for name, sampling_method in sampling_methods.items():\n",
    "        Y_probas = fit_predict_proba_classifier(\n",
    "            X_obs, Y_obs, X_test,\n",
    "            clf=RandomForestClassifier(),\n",
    "            sampling_method=sampling_method,\n",
    "            random_seed=412+i,\n",
    "            y=1,\n",
    "            B=B,  # Number of bootstraps for Deep ensemble\n",
    "        )\n",
    "        Y_pred = np.argmax(Y_probas, axis=1)\n",
    "        method_scores_dict = get_scores(Y_pred, Y_test)\n",
    "        scores_dict[name] = method_scores_dict\n",
    "    # Average scores across iterations\n",
    "    if avg_scores is None:\n",
    "        avg_scores = pd.DataFrame(scores_dict)\n",
    "    else:\n",
    "        avg_scores += pd.DataFrame(scores_dict)\n",
    "avg_scores /= iter\n",
    "# print_scores_table(scores_dict)\n",
    "print(\"DATASET: Diabetes dataset\")\n",
    "print(\"Average scores across iterations:\")\n",
    "display(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df92da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:50<00:00, 10.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oversample_resampling</th>\n",
       "      <th>oversample_random</th>\n",
       "      <th>oversample_smote</th>\n",
       "      <th>undersample_random</th>\n",
       "      <th>no_resampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.826167</td>\n",
       "      <td>0.615807</td>\n",
       "      <td>0.733181</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.539928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.861746</td>\n",
       "      <td>0.777445</td>\n",
       "      <td>0.837706</td>\n",
       "      <td>0.835015</td>\n",
       "      <td>0.743931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.724257</td>\n",
       "      <td>0.825230</td>\n",
       "      <td>0.869395</td>\n",
       "      <td>0.646624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1</th>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.724257</td>\n",
       "      <td>0.825230</td>\n",
       "      <td>0.869395</td>\n",
       "      <td>0.646624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0</th>\n",
       "      <td>0.520917</td>\n",
       "      <td>0.346105</td>\n",
       "      <td>0.426585</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.312443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_1</th>\n",
       "      <td>0.817383</td>\n",
       "      <td>0.574559</td>\n",
       "      <td>0.706629</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.487862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_0</th>\n",
       "      <td>0.906109</td>\n",
       "      <td>0.980331</td>\n",
       "      <td>0.968784</td>\n",
       "      <td>0.890379</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_1</th>\n",
       "      <td>0.987203</td>\n",
       "      <td>0.996179</td>\n",
       "      <td>0.995136</td>\n",
       "      <td>0.984357</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_0</th>\n",
       "      <td>0.370661</td>\n",
       "      <td>0.210905</td>\n",
       "      <td>0.274308</td>\n",
       "      <td>0.319203</td>\n",
       "      <td>0.185936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <td>0.507272</td>\n",
       "      <td>0.338944</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>0.450129</td>\n",
       "      <td>0.300832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision</th>\n",
       "      <td>0.971112</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.966720</td>\n",
       "      <td>0.965690</td>\n",
       "      <td>0.947934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.861746</td>\n",
       "      <td>0.777445</td>\n",
       "      <td>0.837706</td>\n",
       "      <td>0.835015</td>\n",
       "      <td>0.743931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   oversample_resampling  oversample_random  oversample_smote  \\\n",
       "accuracy                        0.826167           0.615807          0.733181   \n",
       "balanced_accuracy               0.861746           0.777445          0.837706   \n",
       "f1                              0.893433           0.724257          0.825230   \n",
       "f1_1                            0.893433           0.724257          0.825230   \n",
       "f1_0                            0.520917           0.346105          0.426585   \n",
       "recall_1                        0.817383           0.574559          0.706629   \n",
       "recall_0                        0.906109           0.980331          0.968784   \n",
       "precision_1                     0.987203           0.996179          0.995136   \n",
       "precision_0                     0.370661           0.210905          0.274308   \n",
       "matthews_corrcoef               0.507272           0.338944          0.426480   \n",
       "average_precision               0.971112           0.954545          0.966720   \n",
       "roc_auc                         0.861746           0.777445          0.837706   \n",
       "\n",
       "                   undersample_random  no_resampling  \n",
       "accuracy                     0.790554       0.539928  \n",
       "balanced_accuracy            0.835015       0.743931  \n",
       "f1                           0.869395       0.646624  \n",
       "f1_1                         0.869395       0.646624  \n",
       "f1_0                         0.466921       0.312443  \n",
       "recall_1                     0.779650       0.487862  \n",
       "recall_0                     0.890379       1.000000  \n",
       "precision_1                  0.984357       1.000000  \n",
       "precision_0                  0.319203       0.185936  \n",
       "matthews_corrcoef            0.450129       0.300832  \n",
       "average_precision            0.965690       0.947934  \n",
       "roc_auc                      0.835015       0.743931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# RANDOM DATA GENERATION\n",
    "from tqdm import tqdm\n",
    "ones_ratio = 0.1\n",
    "\n",
    "sampling_methods = {\n",
    "    \"oversample_resampling\": oversample_resampling,\n",
    "    \"oversample_random\": oversample_random,\n",
    "    \"oversample_smote\": oversample_smote,\n",
    "    \"undersample_random\": undersample_random,\n",
    "    \"no_resampling\": no_resampling,\n",
    "}\n",
    "avg_scores = None\n",
    "iter = 25\n",
    "B = 10\n",
    "\n",
    "\n",
    "for i in tqdm(range(iter)):\n",
    "    X, Y = make_classification(\n",
    "        n_samples=1000,\n",
    "        n_classes=2,\n",
    "        n_features=5,\n",
    "        n_informative=5,\n",
    "        n_redundant=0,\n",
    "        weights=[0.5, 0.5],  # Imbalanced dataset\n",
    "        random_state=421+i\n",
    "    )\n",
    "    # X, Y = make_blobs(centers=2, n_samples=1000, random_state=421+i, cluster_std=2)\n",
    "    X_obs, X_test, Y_obs, Y_test = train_with_few_ones(X, Y, one_ratio=ones_ratio, random_state=421+i)\n",
    "\n",
    "    scores_dict = {}\n",
    "    for name, sampling_method in sampling_methods.items():\n",
    "        Y_probas = fit_predict_proba_classifier(\n",
    "            X_obs, Y_obs, X_test,\n",
    "            clf=RandomForestClassifier(),\n",
    "            sampling_method=sampling_method,\n",
    "            random_seed=412+i,\n",
    "            y=1,\n",
    "            B=B,  # Number of bootstraps for Deep ensemble\n",
    "        )\n",
    "        Y_pred = np.argmax(Y_probas, axis=1)\n",
    "        method_scores_dict = get_scores(Y_pred, Y_test)\n",
    "        scores_dict[name] = method_scores_dict\n",
    "    # Average scores across iterations\n",
    "    if avg_scores is None:\n",
    "        avg_scores = pd.DataFrame(scores_dict)\n",
    "    else:\n",
    "        avg_scores += pd.DataFrame(scores_dict)\n",
    "avg_scores /= iter\n",
    "print(\"DATASET: Randomly generated data\")\n",
    "display(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb66e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae50ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
