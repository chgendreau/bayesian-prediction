{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Predictive Oversampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        26\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.43      0.50      0.46        30\n",
      "weighted avg       0.75      0.87      0.80        30\n",
      "\n",
      "Balanced Accuracy (without oversampling): 0.5\n",
      "F1 Score (without oversampling): 0.0\n",
      "With Predictive Oversampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        26\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.83      0.96      0.88        30\n",
      "weighted avg       0.96      0.93      0.94        30\n",
      "\n",
      "Balanced Accuracy (with oversampling): 0.9615384615384616\n",
      "F1 Score (with oversampling): 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charl/repos/bayesian-prediction/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/charl/repos/bayesian-prediction/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/charl/repos/bayesian-prediction/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate an imbalanced dataset\n",
    "X, y = make_classification(n_samples=100, weights=[0.9, 0.1], \n",
    "                           n_features=2, n_classes=2, n_informative=2, n_redundant=0)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Define predictive distribution (simple Gaussian predictive inference)\n",
    "def predictive_resampling(X_minority, n_new_samples):\n",
    "    mean = X_minority.mean(axis=0)\n",
    "    cov = np.cov(X_minority, rowvar=False)\n",
    "    return np.random.multivariate_normal(mean, cov, n_new_samples)\n",
    "\n",
    "# Original data\n",
    "X_minority = X_train[y_train == 1]\n",
    "n_new_samples = len(X_train[y_train == 0]) - len(X_minority)\n",
    "\n",
    "# Generate synthetic minority samples\n",
    "X_synthetic = predictive_resampling(X_minority, n_new_samples)\n",
    "X_train_augmented = np.vstack([X_train, X_synthetic])\n",
    "y_train_augmented = np.hstack([y_train, np.ones(n_new_samples)])\n",
    "\n",
    "# Classifier without oversampling\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Without Predictive Oversampling:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Balanced Accuracy (without oversampling):\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score (without oversampling):\", f1_score(y_test, y_pred))\n",
    "\n",
    "# Classifier with predictive oversampling\n",
    "clf_aug = LogisticRegression().fit(X_train_augmented, y_train_augmented)\n",
    "y_pred_aug = clf_aug.predict(X_test)\n",
    "print(\"With Predictive Oversampling:\\n\", classification_report(y_test, y_pred_aug))\n",
    "print(\"Balanced Accuracy (with oversampling):\", balanced_accuracy_score(y_test, y_pred_aug))\n",
    "print(\"F1 Score (with oversampling):\", f1_score(y_test, y_pred_aug))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a00e6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vanilla (No Resampling) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.950     0.989     0.969       268\n",
      "           1      0.857     0.562     0.679        32\n",
      "\n",
      "    accuracy                          0.943       300\n",
      "   macro avg      0.903     0.776     0.824       300\n",
      "weighted avg      0.940     0.943     0.938       300\n",
      "\n",
      "Balanced Accuracy: 0.776\n",
      "F1-score (macro): 0.824\n",
      "F1-score (per class): [0.96892139 0.67924528]\n",
      "Matthews Corrcoef: 0.667\n",
      "\n",
      "--- SMOTE Oversampling ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.881     0.929       268\n",
      "           1      0.467     0.875     0.609        32\n",
      "\n",
      "    accuracy                          0.880       300\n",
      "   macro avg      0.725     0.878     0.769       300\n",
      "weighted avg      0.928     0.880     0.895       300\n",
      "\n",
      "Balanced Accuracy: 0.878\n",
      "F1-score (macro): 0.769\n",
      "F1-score (per class): [0.92913386 0.60869565]\n",
      "Matthews Corrcoef: 0.583\n",
      "\n",
      "--- Bayesian Bootstrap Oversampling ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.944     0.964       268\n",
      "           1      0.651     0.875     0.747        32\n",
      "\n",
      "    accuracy                          0.937       300\n",
      "   macro avg      0.818     0.910     0.855       300\n",
      "weighted avg      0.949     0.937     0.941       300\n",
      "\n",
      "Balanced Accuracy: 0.910\n",
      "F1-score (macro): 0.855\n",
      "F1-score (per class): [0.96380952 0.74666667]\n",
      "Matthews Corrcoef: 0.722\n",
      "\n",
      "--- Random Undersampling ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.884     0.931       268\n",
      "           1      0.475     0.875     0.615        32\n",
      "\n",
      "    accuracy                          0.883       300\n",
      "   macro avg      0.729     0.880     0.773       300\n",
      "weighted avg      0.929     0.883     0.898       300\n",
      "\n",
      "Balanced Accuracy: 0.880\n",
      "F1-score (macro): 0.773\n",
      "F1-score (per class): [0.93123772 0.61538462]\n",
      "Matthews Corrcoef: 0.590\n",
      "\n",
      "--- Predictive Oversampling ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.881     0.929       268\n",
      "           1      0.467     0.875     0.609        32\n",
      "\n",
      "    accuracy                          0.880       300\n",
      "   macro avg      0.725     0.878     0.769       300\n",
      "weighted avg      0.928     0.880     0.895       300\n",
      "\n",
      "Balanced Accuracy: 0.878\n",
      "F1-score (macro): 0.769\n",
      "F1-score (per class): [0.92913386 0.60869565]\n",
      "Matthews Corrcoef: 0.583\n",
      "\n",
      "=== Summary Table ===\n",
      "                         method  balanced_accuracy  f1_macro      mcc\n",
      "        Vanilla (No Resampling)           0.775653  0.824083 0.666996\n",
      "             SMOTE Oversampling           0.877799  0.768915 0.583111\n",
      "Bayesian Bootstrap Oversampling           0.909515  0.855238 0.721508\n",
      "           Random Undersampling           0.879664  0.773311 0.589709\n",
      "        Predictive Oversampling           0.877799  0.768915 0.583111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Generate an imbalanced dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, weights=[0.9, 0.1], \n",
    "    n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=42\n",
    ")\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Metrics reporting function\n",
    "def report_scores(y_true, y_pred, method):\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f\"\\n--- {method} ---\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "    print(f\"F1-score (macro): {f1_macro:.3f}\")\n",
    "    print(f\"F1-score (per class): {f1_per_class}\")\n",
    "    print(f\"Matthews Corrcoef: {mcc:.3f}\")\n",
    "    return {\n",
    "        \"method\": method,\n",
    "        \"balanced_accuracy\": bal_acc,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_per_class\": f1_per_class,\n",
    "        \"mcc\": mcc\n",
    "    }\n",
    "\n",
    "# 1. No resampling (Vanilla)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "scores_vanilla = report_scores(y_test, y_pred, \"Vanilla (No Resampling)\")\n",
    "\n",
    "# 2. SMOTE oversampling\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "clf_sm = LogisticRegression().fit(X_train_sm, y_train_sm)\n",
    "y_pred_sm = clf_sm.predict(X_test)\n",
    "scores_smote = report_scores(y_test, y_pred_sm, \"SMOTE Oversampling\")\n",
    "\n",
    "# 3. Bayesian Bootstrap oversampling (Dirichlet weights)\n",
    "def bayesian_bootstrap_resample(X_minority, n_new_samples):\n",
    "    n = X_minority.shape[0]\n",
    "    # Each synthetic point is a convex combination of the observed points with Dirichlet weights\n",
    "    weights = np.random.dirichlet(np.ones(n), n_new_samples)\n",
    "    X_synth = weights @ X_minority  # Matrix multiply (n_new_samples x n) @ (n x d) = (n_new_samples x d)\n",
    "    return X_synth\n",
    "\n",
    "X_minority = X_train[y_train == 1]\n",
    "n_new_samples = len(X_train[y_train == 0]) - len(X_minority)\n",
    "X_synth_bayes = bayesian_bootstrap_resample(X_minority, n_new_samples)\n",
    "X_train_bayes = np.vstack([X_train, X_synth_bayes])\n",
    "y_train_bayes = np.hstack([y_train, np.ones(n_new_samples)])\n",
    "clf_bayes = LogisticRegression().fit(X_train_bayes, y_train_bayes)\n",
    "y_pred_bayes = clf_bayes.predict(X_test)\n",
    "scores_bayes = report_scores(y_test, y_pred_bayes, \"Bayesian Bootstrap Oversampling\")\n",
    "\n",
    "# 4. Random undersampling (majority class)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_us, y_train_us = rus.fit_resample(X_train, y_train)\n",
    "clf_us = LogisticRegression().fit(X_train_us, y_train_us)\n",
    "y_pred_us = clf_us.predict(X_test)\n",
    "scores_us = report_scores(y_test, y_pred_us, \"Random Undersampling\")\n",
    "\n",
    "# 5. Predictive Oversampling (already done above)\n",
    "# Define predictive distribution (simple Gaussian predictive inference)\n",
    "def predictive_resampling(X_minority, n_new_samples):\n",
    "    mean = X_minority.mean(axis=0)\n",
    "    cov = np.cov(X_minority, rowvar=False)\n",
    "    return np.random.multivariate_normal(mean, cov, n_new_samples)\n",
    "\n",
    "# Original data\n",
    "X_minority = X_train[y_train == 1]\n",
    "n_new_samples = len(X_train[y_train == 0]) - len(X_minority)\n",
    "\n",
    "# Generate synthetic minority samples\n",
    "X_synthetic = predictive_resampling(X_minority, n_new_samples)\n",
    "X_train_augmented = np.vstack([X_train, X_synthetic])\n",
    "y_train_augmented = np.hstack([y_train, np.ones(n_new_samples)])\n",
    "# Classifier with predictive oversampling\n",
    "clf_aug = LogisticRegression().fit(X_train_augmented, y_train_augmented)\n",
    "y_pred_aug = clf_aug.predict(X_test)\n",
    "scores_predictive = report_scores(y_test, y_pred_aug, \"Predictive Oversampling\")\n",
    "\n",
    "\n",
    "# Summary Table\n",
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    scores_vanilla,\n",
    "    scores_smote,\n",
    "    scores_bayes,\n",
    "    scores_us,\n",
    "    scores_predictive\n",
    "])\n",
    "\n",
    "# Only show summary scores, not per-class F1 (for table neatness)\n",
    "summary_short = summary[[\"method\", \"balanced_accuracy\", \"f1_macro\", \"mcc\"]]\n",
    "print(\"\\n=== Summary Table ===\")\n",
    "print(summary_short.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6399e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def sample_multivariate_t(mu, Sigma, df, n_samples):\n",
    "    \"\"\"\n",
    "    Draws samples from a multivariate Student-t distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : np.ndarray\n",
    "        Mean vector (d,)\n",
    "    Sigma : np.ndarray\n",
    "        Scale matrix (d, d)\n",
    "    df : float\n",
    "        Degrees of freedom\n",
    "    n_samples : int\n",
    "        Number of samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Samples (n_samples, d)\n",
    "    \"\"\"\n",
    "    d = len(mu)\n",
    "    g = np.tile(np.random.gamma(df/2., 2./df, n_samples), (d,1)).T  # shape (n_samples, d)\n",
    "    Z = np.random.multivariate_normal(np.zeros(d), Sigma, n_samples)\n",
    "    return mu + Z / np.sqrt(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd6f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_predictive_parameters(X):\n",
    "    \"\"\"\n",
    "    Returns parameters for posterior predictive multivariate t:\n",
    "        mean, scale, dof\n",
    "    Uses conjugate normal-inverse-Wishart prior (weak, uninformative)\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    mu = X.mean(axis=0)\n",
    "    S = np.cov(X, rowvar=False)\n",
    "    # Weak prior: prior mean = sample mean, prior kappa = 1e-6, prior dof = d+2\n",
    "    kappa_0 = 1e-6\n",
    "    nu_0 = d + 2\n",
    "    # Posterior parameters\n",
    "    kappa_n = kappa_0 + n\n",
    "    nu_n = nu_0 + n\n",
    "    mu_n = (kappa_0 * mu + n * mu) / kappa_n\n",
    "    S_n = S + (kappa_0 * n) / kappa_n * np.outer(mu - mu, mu - mu)\n",
    "    # Predictive mean, scale, dof\n",
    "    mean_pred = mu_n\n",
    "    scale_pred = S_n * (kappa_n + 1) / (kappa_n * (nu_n - d + 1))\n",
    "    df_pred = nu_n - d + 1\n",
    "    return mean_pred, scale_pred, df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b58dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X_train, y_train are already defined and minority class is 1\n",
    "X_minority = X_train[y_train == 1]\n",
    "n_majority = np.sum(y_train == 0)\n",
    "n_minority = np.sum(y_train == 1)\n",
    "n_new_samples = n_majority - n_minority\n",
    "\n",
    "# Get posterior predictive parameters\n",
    "mu_pred, Sigma_pred, df_pred = bayesian_predictive_parameters(X_minority)\n",
    "\n",
    "# Sample synthetic minority points\n",
    "X_synth = sample_multivariate_t(mu_pred, Sigma_pred, df_pred, n_new_samples)\n",
    "y_synth = np.ones(n_new_samples)  # class label\n",
    "\n",
    "# Augment training data\n",
    "X_train_aug = np.vstack([X_train, X_synth])\n",
    "y_train_aug = np.hstack([y_train, y_synth])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b888528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       268\n",
      "           1       0.86      0.56      0.68        32\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.90      0.78      0.82       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n",
      "Bayesian Predictive Resampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       268\n",
      "           1       0.65      0.88      0.75        32\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.82      0.91      0.86       300\n",
      "weighted avg       0.95      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "clf_bayes = LogisticRegression().fit(X_train_aug, y_train_aug)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_bayes = clf_bayes.predict(X_test)\n",
    "\n",
    "print(\"Original Data:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Bayesian Predictive Resampling:\\n\", classification_report(y_test, y_pred_bayes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cea858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
